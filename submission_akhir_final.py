# -*- coding: utf-8 -*-
"""Copy of Submission_Akhir_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MlWGLVVVe3VPaYCs9YlGICMb7e_o-Vhw

# Proyek Klasifikasi Gambar: [Garbage-Dataset]
- **Nama:** Ilham Sholahuddin
- **Email:** ilhamsholahuddin161@gmail.com
- **ID Dicoding:** ilham_sholahuddin16

## Import Semua Packages/Library yang Digunakan
"""

import os, shutil
import zipfile
import random
from random import sample
import shutil
from shutil import copyfile
import pathlib
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from tqdm.notebook import tqdm as tq

# Libraries untuk pemrosesan data gambar
import cv2
from PIL import Image
import skimage
from skimage import io
from skimage.transform import resize
from skimage.transform import rotate, AffineTransform, warp
from skimage import img_as_ubyte
from skimage.exposure import adjust_gamma
from skimage.util import random_noise

# Libraries untuk pembangunan model
import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras import layers, models, regularizers
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.applications import MobileNet
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau

"""## Data Preparation"""

# Import module untuk upload file
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle*.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download kaggle dataset
!kaggle datasets download -d sumn2u/garbage-classification-v2 -p /content/data

# Unzip Dataset
!unzip /content/data/garbage-classification-v2.zip -d /content/dataset

"""### Data Loading

**Data Exploration**
"""

BASE_PATH = Path('/content/dataset/garbage-dataset')

for root, dirs, files in os.walk(BASE_PATH):
    if len(dirs) > 0 and len(files) == 0:
        data_dir = root
        break

print(f"Data directory: {data_dir}")
print(f"\nKelas yang tersedia:")

# Hitung jumlah gambar per kelas
classes = sorted(os.listdir(data_dir))
class_counts = {}

for class_name in classes:
    class_path = os.path.join(data_dir, class_name)
    if os.path.isdir(class_path):
        count = len(os.listdir(class_path))
        class_counts[class_name] = count
        print(f"  - {class_name}: {count} gambar")

total_images = sum(class_counts.values())
print(f"\nTotal gambar: {total_images}")
print(f"Jumlah kelas: {len(class_counts)}")

# Visualisasi sample gambar dari setiap kelas
fig, axes = plt.subplots(2, 5, figsize=(15, 6))
axes = axes.ravel()

for i, class_name in enumerate(classes[:10]):
    class_path = os.path.join(data_dir, class_name)
    if os.path.isdir(class_path):
        images = os.listdir(class_path)
        if len(images) > 0:
            img_path = os.path.join(class_path, images[0])
            img = load_img(img_path, target_size=(150, 150))
            axes[i].imshow(img)
            axes[i].set_title(class_name, fontsize=10)
            axes[i].axis('off')

plt.tight_layout()
plt.show()

# Visualisasi distribusi kelas
plt.figure(figsize=(12, 6))
bars = plt.bar(class_counts.keys(), class_counts.values(), color='skyblue', edgecolor='navy', linewidth=1.5)

# Tambahkan nilai di atas bar
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{int(height)}',
             ha='center', va='bottom', fontsize=10, fontweight='bold')

plt.xlabel('Kelas Garbage', fontsize=12, fontweight='bold')
plt.ylabel('Jumlah Gambar', fontsize=12, fontweight='bold')
plt.title('Distribusi Dataset per Kelas', fontsize=14, fontweight='bold')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.3, linestyle='--')
plt.tight_layout()
plt.show()

"""### Data Preprocessing

#### Split Dataset
"""

data_dir = "/content/dataset/garbage-dataset"
output_base = "/content/split_dataset"

TRAIN_RATIO = 0.7
VAL_RATIO = 0.2
TEST_RATIO = 0.1

train_dir = f"{output_base}/train"
val_dir = f"{output_base}/val"
test_dir = f"{output_base}/test"

for p in [train_dir, val_dir, test_dir]:
    os.makedirs(p, exist_ok=True)

classes = sorted(os.listdir(data_dir))

print(" Splitting dataset...\n")

for cls in tq(classes):
    src = os.path.join(data_dir, cls)
    if not os.path.isdir(src):
        continue

    # buat folder kelas
    os.makedirs(os.path.join(train_dir, cls), exist_ok=True)
    os.makedirs(os.path.join(val_dir, cls), exist_ok=True)
    os.makedirs(os.path.join(test_dir, cls), exist_ok=True)

    images = [f for f in os.listdir(src) if f.lower().endswith(("jpg","png","jpeg"))]
    random.shuffle(images)

    n = len(images)
    n_train = int(n * TRAIN_RATIO)
    n_val = int(n * VAL_RATIO)

    train_imgs = images[:n_train]
    val_imgs   = images[n_train:n_train+n_val]
    test_imgs  = images[n_train+n_val:]

    # Copy images
    for img in train_imgs:
        shutil.copy2(os.path.join(src, img), os.path.join(train_dir, cls, img))

    for img in val_imgs:
        shutil.copy2(os.path.join(src, img), os.path.join(val_dir, cls, img))

    for img in test_imgs:
        shutil.copy2(os.path.join(src, img), os.path.join(test_dir, cls, img))

print(" Dataset splitting completed!")

# Verify split
def count_files(directory):
    total = 0
    for root, dirs, files in os.walk(directory):
        total += len([f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
    return total

train_count = count_files(train_dir)
val_count = count_files(val_dir)
test_count = count_files(test_dir)

print(f" Hasil Split:")
print(f" Train: {train_count} gambar ({train_count/total_images*100:.1f}%)")
print(f" Validation: {val_count} gambar ({val_count/total_images*100:.1f}%)")
print(f" Test: {test_count} gambar ({test_count/total_images*100:.1f}%)")
print(f" Total: {train_count + val_count + test_count} gambar")

"""#### Data Cleaning"""

# Folder Dataset hasil split
train_dir = "/content/split_dataset/train"
val_dir   = "/content/split_dataset/val"
test_dir  = "/content/split_dataset/test"

def scan_and_clean(folder):
    bad_files = []
    allowed_ext = (".jpg", ".jpeg", ".png", ".bmp", ".gif")

    for root, dirs, files in os.walk(folder):
        for f in files:
            path = os.path.join(root, f)

            # Skip jika ekstensi bukan standar
            if not f.lower().endswith(allowed_ext):
                bad_files.append(path)
                continue

            # Coba buka file
            try:
                img = Image.open(path)
                img.verify()   # check corrupt
            except:
                bad_files.append(path)

    print(f"\nFound {len(bad_files)} bad files:")
    for bf in bad_files:
        print(" -", bf)

    # auto delete
    for bf in bad_files:
        os.remove(bf)
    print("\nAll bad files removed!")


scan_and_clean(train_dir)
scan_and_clean(val_dir)
scan_and_clean(test_dir)

import os

for folder in [train_dir, val_dir, test_dir]:
    print("\nChecking:", folder)
    for root, dirs, files in os.walk(folder):
        for f in files:
            if not f.lower().endswith((".jpg",".jpeg",".png",".bmp",".gif")):
                print("Non-image file:", os.path.join(root, f))

def check_rgba(folder):
    for root, dirs, files in os.walk(folder):
        for f in files:
            if f.lower().endswith(".png"):
                p = os.path.join(root, f)
                try:
                    img = Image.open(p)
                    if img.mode != "RGB":
                        print("RGBA or Gray image:", p, "mode:", img.mode)
                except:
                    pass

check_rgba(train_dir)
check_rgba(val_dir)
check_rgba(test_dir)

folders = [
    "/content/split_dataset/train",
    "/content/split_dataset/val",
    "/content/split_dataset/test"
]

print("Converting RGBA → RGB ...")

for folder in folders:
    for root, _, files in os.walk(folder):
        for f in files:
            if f.lower().endswith(".png"):
                path = os.path.join(root, f)
                try:
                    img = Image.open(path)
                    if img.mode != "RGB":
                        print("Fixing:", path, "mode:", img.mode)
                        rgb = img.convert("RGB")
                        rgb.save(path)
                except Exception as e:
                    print("Error reading:", path, e)

print("\nAll RGBA images converted to RGB!")

def clean_tf_decode(root_dir):
    print(f"\n Checking TensorFlow decode compatibility in: {root_dir}\n")
    removed = 0
    checked = 0

    for folder, _, files in os.walk(root_dir):
        for file in files:
            path = os.path.join(folder, file)
            checked += 1

            try:
                raw = tf.io.read_file(path)
                _ = tf.io.decode_image(raw, channels=3)
            except:
                print(f"Removing corrupt file: {path}")
                removed += 1
                os.remove(path)

    print(f"\nDone scanning: {root_dir}")
    print(f"Total files checked: {checked}")
    print(f"Total removed: {removed}\n")
    return removed

# Jalankan untuk semua split
removed_train = clean_tf_decode(train_dir)
removed_val   = clean_tf_decode(val_dir)
removed_test  = clean_tf_decode(test_dir)

print(" FINAL SUMMARY")
print("Removed from train:", removed_train)
print("Removed from val:", removed_val)
print("Removed from test:", removed_test)

"""#### Load Dataset Preprocessing"""

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
AUTOTUNE = tf.data.AUTOTUNE

raw_train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    train_dir,
    seed=42,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    label_mode="int",
    shuffle=True
)
raw_val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    val_dir,
    seed=42,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    label_mode="int",
    shuffle=False
)
raw_test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    test_dir,
    seed=42,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    label_mode="int",
    shuffle=False
)

class_names = raw_train_ds.class_names
num_classes = len(class_names)

print(class_names)

"""#### Augmentasi + Normalisasi"""

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.05),
    layers.RandomZoom(0.1),
    layers.RandomContrast(0.1),
])

def preprocess(ds, training=True):
    # Augmentasi untuk training saja
    if training:
        ds = ds.map(
            lambda x, y: (data_augmentation(x), y),
            num_parallel_calls=AUTOTUNE
        )

    # Normalisasi ke 0–1
    ds = ds.map(
        lambda x, y: (tf.cast(x, tf.float32) / 255.0, y),
        num_parallel_calls=AUTOTUNE
    )

    return ds.prefetch(AUTOTUNE)

train_ds = preprocess(raw_train_ds, training=True)
val_ds   = preprocess(raw_val_ds, training=False)
test_ds  = preprocess(raw_test_ds, training=False)

"""## Modelling"""

# Base model pretrained
base = MobileNetV2(
    include_top=False,
    weights="imagenet",
    input_shape=(224, 224, 3)
)
base.trainable = False

model = models.Sequential([
    layers.Input(shape=(224,224,3)),
    base,
    layers.Conv2D(64, (3,3), activation='relu', padding='same'),
    layers.MaxPooling2D(),

    layers.Conv2D(128, (3,3), activation='relu', padding='same'),
    layers.MaxPooling2D(),

    layers.GlobalAveragePooling2D(),

    layers.Dense(256, activation='relu'),
    layers.Dropout(0.3),

    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-3),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

model.summary()

"""#### Training Model"""

es = tf.keras.callbacks.EarlyStopping(
    patience=5,
    restore_best_weights=True,
    monitor="val_loss"
)

lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_loss",
    factor=0.3,
    patience=2,
    min_lr=1e-6
)

ckpt = tf.keras.callbacks.ModelCheckpoint(
    "mobilenetv2_stage1.keras",
    save_best_only=True,
    monitor="val_loss"
)

history1 = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,
    callbacks=[es, lr, ckpt]
)

"""#### **Fine-Tune**"""

# Load Model Training awal
model = tf.keras.models.load_model("mobilenetv2_stage1.keras")
print("Loaded best initial model!")

# Unfreeze sebagian layer MobileNetV2
base_model = model.layers[0]
base_model.trainable = True

# Freeze sebagian besar layer bawah
for layer in base_model.layers[:-50]:
    layer.trainable = False

# Compile ulang dengan VERY LOW LR
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Callback untuk step Fine-Tune
ft_es = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

ft_ckpt = ModelCheckpoint(
    "best_model_final.keras",
    monitor='val_loss',
    save_best_only=True
)

ft_lr = ReduceLROnPlateau(
    monitor='val_loss',
    patience=2,
    factor=0.3,
    min_lr=1e-7
)

history_ft = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,
    callbacks=[ft_es, ft_lr, ft_ckpt]
)

"""## Evaluasi dan Visualisasi

#### **Plot Training vs Validation (Accuracy & Loss)**
"""

def plot_history(history1):
    # Training awal - Accuracy
    plt.figure(figsize=(7,5))
    plt.plot(history1.history['accuracy'], label='Train Acc (Stage 1)')
    plt.plot(history1.history['val_accuracy'], label='Val Acc (Stage 1)')
    plt.title("History 1 - Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)
    plt.show()

    # Training awal - Loss
    plt.figure(figsize=(7,5))
    plt.plot(history1.history['loss'], label='Train Loss (Stage 1)')
    plt.plot(history1.history['val_loss'], label='Val Loss (Stage 1)')
    plt.title("History 1 - Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.show()
plot_history(history1)

def plot_history_ft(history_ft):
 # Fine-Tuning - Accuracy
        plt.figure(figsize=(7,5))
        plt.plot(history_ft.history['accuracy'], label='Train Acc (Fine-Tune)')
        plt.plot(history_ft.history['val_accuracy'], label='Val Acc (Fine-Tune)')
        plt.title("History 2 - Accuracy (Fine-Tuning)")
        plt.xlabel("Epoch")
        plt.ylabel("Accuracy")
        plt.legend()
        plt.grid(True)
        plt.show()



        # fine Tuning - Loss
        plt.figure(figsize=(7,5))
        plt.plot(history_ft.history['loss'], label='Train Loss (Fine-Tune)')
        plt.plot(history_ft.history['val_loss'], label='Val Loss (Fine-Tune)')
        plt.title("History 2 - Loss (Fine-Tuning)")
        plt.xlabel("Epoch")
        plt.ylabel("Loss")
        plt.legend()
        plt.grid(True)
        plt.show()
plot_history_ft(history_ft)

"""#### **Evaluasi Model Final di Test Set**"""

test_loss, test_acc = model.evaluate(test_ds)
print("\n Final Test Accuracy:", test_acc)
print("Final Test Loss:", test_loss)

"""#### **Confusion Matrix**"""

y_true = []
y_pred = []


for images, labels in test_ds:
    preds = model.predict(images, verbose=0)
    y_true.extend(labels.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

cm = confusion_matrix(y_true, y_pred)

plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, cmap='Blues', fmt='d')
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""#### **Classification Report**"""

print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=class_names))

"""#### **Percobaan Prediksi Gambar**"""

def predict_single_image(img_path):
    img = load_img(img_path, target_size=IMG_SIZE)
    img_array = img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.cast(img_array, tf.float32) / 255.0

    predictions = model.predict(img_array, verbose=0)
    predicted_class_index = np.argmax(predictions[0])
    confidence = np.max(predictions[0])

    return predicted_class_index, confidence, img


# Plot sample predictions
num_classes = len(class_names)
rows = (num_classes // 4) + (1 if num_classes % 4 != 0 else 0)

plt.figure(figsize=(16, rows * 4))

for i, class_name in enumerate(class_names):
    class_path = os.path.join(test_dir, class_name)
    files = [f for f in os.listdir(class_path)
             if f.lower().endswith((".jpg", ".jpeg", ".png"))]

    if len(files) == 0:
        print(f"Tidak ada gambar untuk kelas: {class_name}")
        continue

    # Pilih Gambar Secara Acak
    img_path = os.path.join(class_path, random.choice(files))

    pred_idx, confidence, img = predict_single_image(img_path)

    plt.subplot(rows, 4, i+1)
    plt.imshow(img)
    plt.title(
        f"True: {class_name}\nPred: {class_names[pred_idx]} ({confidence*100:.1f}%)",
        fontsize=10
    )
    plt.axis("off")

plt.suptitle("Prediksi Gambar per Kelas (Acak)", fontsize=18, fontweight="bold", y=1.02)
plt.tight_layout()
plt.show()

"""## Konversi Model

#### **SavedModel**
"""

model.export("savedmodel_garbage_classifier")
print("SavedModel created!")

"""#### **Convert ke TFLite**"""

converter = tf.lite.TFLiteConverter.from_saved_model("savedmodel_garbage_classifier")
tflite_model = converter.convert()

with open("garbage_model.tflite", "wb") as f:
    f.write(tflite_model)

print("TFLite created!")

"""#### **Convert ke TensorFlow.js**"""

!pip install tensorflowjs

!tensorflowjs_converter \
    --input_format=tf_saved_model \
    --output_format=tfjs_graph_model \
    savedmodel_garbage_classifier \
    tfjs_garbage_model

"""### **Inference menggunakan SavedModel**"""

# Load savedmodel
loaded = tf.saved_model.load("/content/savedmodel_garbage_classifier")
infer = loaded.signatures["serving_default"]

# Check available keys
output_keys = list(infer.structured_outputs.keys())
print("Output keys:", output_keys)

# Use the first key (pasti softmax layer)
output_key = output_keys[0]

img_path = "/content/dataset/garbage-dataset/plastic/plastic_1027.jpg"

# Preprocess
img = image.load_img(img_path, target_size=(224, 224))
img_arr = image.img_to_array(img)
img_arr = np.expand_dims(img_arr, axis=0) / 255.0

# Run inference
output = infer(tf.constant(img_arr))[output_key].numpy()
pred_class = np.argmax(output)

print("Prediction:", pred_class)

plt.imshow(img)
print("Predicted label:", class_names[pred_class])
plt.title(f"Predicted: {class_names[pred_class]}")
plt.axis("off")
plt.show()

"""#### Ambil Library yang digunakan"""

!zip -r models1.zip /content/savedmodel_garbage_classifier

!zip -r models.zip /content/tfjs_garbage_model

!pip freeze requirements.txt